## 1. The Spark DataFrame: An Introduction ##

census = sc.textFile('census_2010.json')
                     
census.take(5)
                     
                     















## 2. Reading in Data ##

# Import SQLContext
from pyspark.sql import SQLContext

# Pass in the SparkContext object `sc`
sqlCtx = SQLContext(sc)

# Read JSON data into a DataFrame object `df`
df = sqlCtx.read.json("census_2010.json")

# Print the type
print(type(df))

## 3. Schema ##

sqlCtx = SQLContext(sc)
df = sqlCtx.read.json("census_2010.json")

df.printSchema()




## 4. Pandas vs Spark DataFrames ##

df.show(5)

## 5. Row Objects ##

first_five = df.head(5)

for line in first_five:
    age = line.age
    print(age)




## 6. Selecting Columns ##

#df[['age']].show()

df.select('age','males','females').show()






## 7. Filtering Rows ##

def sup_five(row):
    if int(row.age) >5:
        return True
    else:
        return False

fives_plus = df[df['age']>5]
                       
fives_plus.show()                       
                
                




## 8. Using Column Comparisons as Filters ##

df[df['males']>df['females']].show(20)



## 9. Converting Spark DataFrames to pandas DataFrames ##

pandas_df = df.toPandas()

#pandas_df.hist(column='total')

pandas_df['total'].hist()


