{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP - Classifier du texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from sklearn.datasets import fetch_rcv1\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction d'importation des données Reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour importer les données depuis la fonction packagée fecth_rcv1\n",
    "def Importer_Donnees_Reuters(Action, nombreLignes):\n",
    "    # On exécute l'action qu'une seule fois pour préserver les ressources mémoire\n",
    "    if(Action):\n",
    "        data = fetch_rcv1(\n",
    "            data_home=\"E:\\\\Data\\\\RawData\\\\Exploit_data_texte\\\\Reuters\",\n",
    "            subset='train')\n",
    "        \n",
    "        Index = [data.sample_id]\n",
    "        Labels = [data.target_names]\n",
    "        \n",
    "        # On réduit les datasets à 300 lignes en raison de ressources mémoire limitées\n",
    "        Features = pd.DataFrame(data.data.A)\n",
    "        Features_Slice = Features.iloc[:nombreLignes,:]        \n",
    "        \n",
    "        Classifications = pd.DataFrame(data.target.A,columns=Labels)\n",
    "        Classifications_Slice = Classifications.iloc[:nombreLignes,:]\n",
    "        \n",
    "        # On libère la mémoire en supprimant les variables contenant les données source\n",
    "        del data\n",
    "        del Features\n",
    "        del Classifications\n",
    "\n",
    "        # On exporte les 2 datasets vers des fichiers CSV enregistrés en local\n",
    "        Features_Slice.to_csv('Features')\n",
    "        Classifications_Slice.to_csv('Classifications')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du jeu de données d'apprentissage et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création dujeu de test d'apprentissage et de test\n",
    "def Construction_Jeu_Donnees():\n",
    "    # On importe les données depuis des fichiers plats stockés en local pour éviter les \"Error Memory\"\n",
    "    Classifications_Slice = pd.read_csv(\"E:\\Data\\RawData\\Exploit_data_texte\\Reuters\\Classifications\")\n",
    "    Features_Slice = pd.read_csv(\"E:\\Data\\RawData\\Exploit_data_texte\\Reuters\\Features\")\n",
    "\n",
    "    # On expurge le libellé des index insérés par la fonction d'export en CSV\n",
    "    Features = Features_Slice.iloc[:,1:]\n",
    "    Classifications = Classifications_Slice.iloc[:,1:]\n",
    "\n",
    "    # On construit les jeux de données de test et de training\n",
    "    Features_Train, Features_Test, Labels_Train, Labels_Test = train_test_split(\n",
    "                                                            Features, \n",
    "                                                            Classifications, \n",
    "                                                            test_size=0.30)\n",
    "    \n",
    "    return Features_Train,Features_Test,Labels_Train,Labels_Test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'un classifieur de type arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un classifieur de type Arbre de décision\n",
    "def Classifieur_Arbre_Decision(Features_Train,Features_Test,Labels_Train,Labels_Test):\n",
    "    # Classification Simple\n",
    "    Classification = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "    Classification.fit(Features_Train,Labels_Train)\n",
    "    Score = Classification.score(Features_Test,Labels_Test)\n",
    "    print(\"Le score lambda de la classification par arbre de décision est de : {} \".format(Score))\n",
    "    \n",
    "    # Classification avec validation croisée des différents paramètres\n",
    "    parameters = {\"max_depth\": range(3,20), \n",
    "                  \"random_state\":[0]}\n",
    "    \n",
    "    grid_obj = GridSearchCV(\n",
    "            estimator=Classification,\n",
    "            param_grid=parameters)\n",
    "    \n",
    "    grid_fit =grid_obj.fit(Features_Train,Labels_Train)\n",
    "    print(\"Les paramètres optimums sont : {} \".format(grid_fit.best_params_))\n",
    "    \n",
    "    ScoreCV = grid_fit.score(Features_Test,Labels_Test)\n",
    "    print(\"Le score de la classification avec validation croisée par arbre de décision est de : {} \".format(ScoreCV))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'un classifieur de type KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un classifieur de type KNeighbors\n",
    "def Classifieur_KNeighbors(Features_Train,Features_Test,Labels_Train,Labels_Test):\n",
    "    # Classification Simple\n",
    "    Classification = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "    Classification.fit(Features_Train,Labels_Train)\n",
    "    Score = Classification.score(Features_Test,Labels_Test)\n",
    "    print(\"Le score lambda de la classification par KNeighbors est de : {} \".format(Score))\n",
    "    \n",
    "    # Classification avec validation croisée des différents paramètres\n",
    "    parameters = {\"n_neighbors\": range(2,10), \n",
    "                  \"weights\":['uniform','distance'],\n",
    "                  \"algorithm\":['ball_tree','kd_tree','brute','auto'],\n",
    "                  \"p\":[1,2]}\n",
    "    \n",
    "    grid_obj = GridSearchCV(\n",
    "            estimator=Classification,\n",
    "            param_grid=parameters)\n",
    "    \n",
    "    grid_fit =grid_obj.fit(Features_Train,Labels_Train)\n",
    "    print(\"Les paramètres optimums sont : {} \".format(grid_fit.best_params_))\n",
    "    \n",
    "    ScoreCV = grid_fit.score(Features_Test,Labels_Test)\n",
    "    print(\"Le score de la classification avec validation croisée par KNeighbors est de : {} \".format(ScoreCV))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'un classifieur de type Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un classifieur de type Random Forest\n",
    "def Classifieur_Random_Forest(Features_Train,Features_Test,Labels_Train,Labels_Test):\n",
    "    # Classification Simple\n",
    "    Classification = RandomForestClassifier(bootstrap=True, \n",
    "                                             class_weight=None, \n",
    "                                             criterion='gini',\n",
    "                                             max_depth=2,\n",
    "                                             random_state=0)             \n",
    "\n",
    "    Classification.fit(Features_Train,Labels_Train)\n",
    "    Score = Classification.score(Features_Test,Labels_Test)\n",
    "    print(\"Le score lamda de la classification par Random Forest est de : {} \".format(Score))\n",
    "    \n",
    "    # Classification avec validation croisée des différents paramètres\n",
    "    parameters = {\"n_estimators\": range(5,15), \n",
    "                  \"criterion\":['gini','entropy'],\n",
    "                  \"max_depth\": range(3,10),\n",
    "                  \"bootstrap\":[True,False],\n",
    "                  \"random_state\":[0]}\n",
    "    \n",
    "    grid_obj = GridSearchCV(\n",
    "            estimator=Classification,\n",
    "            param_grid=parameters)\n",
    "    \n",
    "    grid_fit =grid_obj.fit(Features_Train,Labels_Train)\n",
    "    print(\"Les paramètres optimums sont : {} \".format(grid_fit.best_params_))\n",
    "    \n",
    "    ScoreCV = grid_fit.score(Features_Test,Labels_Test)\n",
    "    print(\"Le score de la classification avec validation croisée par Random Forest est de : {} \".format(ScoreCV))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction de transformation d'un vecteur multi-labels binarisé en nombre base 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction permettant de transformer une sortie multi_labels binaires en sortie encodée en base 10\n",
    "def Transformation_Base_2_Vers_Base_10(Octets):\n",
    "    valeur_base_10 = []\n",
    "    \n",
    "    for octet in Octets.iterrows():\n",
    "        valeur_octet = 0\n",
    "        position_bit = 0\n",
    "        \n",
    "        for bit in octet[1]:\n",
    "            valeur_octet += (2**position_bit)*(int(bit))\n",
    "            position_bit += 1\n",
    "        \n",
    "        valeur_base_10.append(valeur_octet)\n",
    "    \n",
    "    return valeur_base_10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction de création d'un classifieur One Versus Rest (estimateur non multi-labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un classifieur de type Random Forest\n",
    "def Classifieur_One_Versus_All(Features_Train,Features_Test,Labels_Train,Labels_Test):\n",
    "    # Classification Simple\n",
    "    Classification = OneVsRestClassifier(\n",
    "                            SVC(\n",
    "                                    C=10,\n",
    "                                    kernel=\"linear\",\n",
    "                                    degree=1,\n",
    "                                    probability =True,\n",
    "                                    max_iter=-1))\n",
    "              \n",
    "    Classification.fit(Features_Train,Labels_Train)\n",
    "    Score = Classification.score(Features_Test,Labels_Test)\n",
    "    print(\"Le score lamda de la classification One Versus Rest est de : {} \".format(Score))\n",
    "    \n",
    "    # Classification avec validation croisée des différents paramètres\n",
    "    parameters = {\"C\": np.arange(1,10,1), \n",
    "                  \"kernel\":[\"linear\",\"rbf\",\"sigmoid\"],\n",
    "                  \"degree\": range(1,5)}\n",
    "    \n",
    "    grid_obj = GridSearchCV(\n",
    "            estimator=Classification,\n",
    "            param_grid=parameters)\n",
    "    \n",
    "    grid_fit =grid_obj.fit(Features_Train,Labels_Train)\n",
    "    print(\"Les paramètres optimums sont : {} \".format(grid_fit.best_params_))\n",
    "    \n",
    "    ScoreCV = grid_fit.score(Features_Test,Labels_Test)\n",
    "    print(\"Le score de la classification avec validation croisée par One Versus Rest est de : {} \".format(ScoreCV))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programme principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constitution des jeux de données\n",
    "Importer_Donnees_Reuters(False,300)\n",
    "\n",
    "Features_Train,Features_Test,Labels_Train,Labels_Test = Construction_Jeu_Donnees()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Classifieur Arbre de décision\n",
      "Le score lambda de la classification par arbre de décision est de : 0.25555555555555554 \n",
      "Les paramètres optimums sont : {'max_depth': 15, 'random_state': 0} \n",
      "Le score de la classification avec validation croisée par arbre de décision est de : 0.23333333333333334 \n"
     ]
    }
   ],
   "source": [
    "# On va choisir 3 types de classifieurs distints\n",
    "\n",
    "# A noter que le jeu de données nous contraint dans le choix des types de classifieur\n",
    "# Nous devons choisir un classifieur acceptant des sorties multi labels\n",
    "# En effet, un document peut avoir plusieurs labels d'apartenance en sortie\n",
    "\n",
    "print(\"1 - Classifieur Arbre de décision\")\n",
    "Classifieur_Arbre_Decision(Features_Train,Features_Test,Labels_Train,Labels_Test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 - Classifieur KNeighbors\n",
      "Le score lambda de la classification par KNeighbors est de : 0.28888888888888886 \n",
      "Les paramètres optimums sont : {'algorithm': 'ball_tree', 'n_neighbors': 2, 'p': 2, 'weights': 'distance'} \n",
      "Le score de la classification avec validation croisée par KNeighbors est de : 0.24444444444444444 \n"
     ]
    }
   ],
   "source": [
    "print(\"2 - Classifieur KNeighbors\")\n",
    "Classifieur_KNeighbors(Features_Train,Features_Test,Labels_Train,Labels_Test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sans surprise, le classificateur des Random Forest s'avère très long... même sur un petit échantillon !!\n",
    "# En effet, le Random Forest tentant de réduire le nombre de Features à chaque itération, le nombre de combinaisons \n",
    "# possibles sur plus de 40 000 Features rendent l'opération très coûteuse en ressources de calcul..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 - Classifieur Random Forest\n",
      "Le score lamda de la classification par Random Forest est de : 0.0 \n",
      "Les paramètres optimums sont : {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 9, 'n_estimators': 5, 'random_state': 0} \n",
      "Le score de la classification avec validation croisée par Random Forest est de : 0.022222222222222223 \n"
     ]
    }
   ],
   "source": [
    "print(\"3 - Classifieur Random Forest\")\n",
    "Classifieur_Random_Forest(Features_Train,Features_Test,Labels_Train,Labels_Test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les scores obtenus ne sont pas pertinents dans la mesure où il serait nécessaire d'entraîner l'intégralité \n",
    "# des dizaines de milliers de samples de la base de training pour avoir une classification pertinente,étant donné\n",
    "# que le nombre de features en entrée dépasse les 40 000 unités !!!\n",
    "\n",
    "# Les ressources de notre ordinateur s'avèrent trop faibles pour réaliser ce traitement...\n",
    "# On se contente donc de livrer le code opérationnel d'un traitement qu'il faudrait exécuter dans une infrastructure Cloud\n",
    "## Amazon ou Azure par exemple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse complémentaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La sortie en prédiction du jeu de données est un vecteur à 134 dimensions\n",
    "# C'est à dire que la prédiction de la classification doit être multi labels (un sample peut être à la fois A, B et C)\n",
    "# De ce fait,cela limite le choix de classificateurs possibles...\n",
    "\n",
    "# Pour s'affranchir de cette limite, on va tenter de changer de base le vecteur de résultat\n",
    "# Le vecteur de sortie étant un tuple de valeurs binaires (0 ou 1)\n",
    "# On peut essayer de transformer ce tuple binaire en base 10, ce qui nous permettrait d'obtenir une valeur numérique base 10\n",
    "\n",
    "# Cette transformation réalisée, on pourra alors choisir un classificateur ne supportant pas les sorties multi-labels\n",
    "# Nous allons effectuer un essai avec un classificateur de type One Versus Rest..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 - Classifieur Régression logistique\n"
     ]
    }
   ],
   "source": [
    "print(\"4 - Classifieur Régression logistique\")\n",
    "\n",
    "# On initialise un encodage pour s'affranchir des avertissements sur les labels absents dans les datasets de training\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Transformation problème multi-classes et multi-labels en problème multi-classes mais label unique\n",
    "# Pour cela, on transforme le vecteur binaire en valeur entière en base 10\n",
    "\n",
    "Labels_Train_Binarisee = le.fit_transform(Transformation_Base_2_Vers_Base_10(Labels_Train))\n",
    "Labels_Test_Binarisee = le.fit_transform(Transformation_Base_2_Vers_Base_10(Labels_Test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cela nous permet alors d'utiliser d'autres types de classifieurs\n",
    "Classifieur_One_Versus_All(Features_Train,Features_Test,Labels_Train_Binarisee,Labels_Test_Binarisee)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le score lamda de la classification One Versus Rest est de : 0.011111111111111112 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Au final, le résultat ne semble pas particulièrement probant...\n",
    "# De nombreuses difficultés viennent entraver cette méthode (classe trop peu peuplée, labels absents dans la base de training)\n",
    "\n",
    "# Cette manipulation ne permet pas de s'affranchir de l'important besoin en ressources nécessaires pour manipuler\n",
    "# un dataset aussi exigeant (nombre très important de features) !!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
