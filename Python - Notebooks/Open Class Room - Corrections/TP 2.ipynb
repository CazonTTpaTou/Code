{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par charger les données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('winequality-red.csv', sep=\";\")\n",
    "\n",
    "X = data.as_matrix(data.columns[:-1])\n",
    "y = data.as_matrix([data.columns[-1]])\n",
    "y = y.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Séparons nos données en un jeu de test et un jeu d'entraînement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "model_selection.train_test_split(X, y,\n",
    "test_size=0.3 # 30% des données dans le jeu de test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardisons les données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "std_scale = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_std = std_scale.transform(X_train)\n",
    "X_test_std = std_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Réalisons une régression Knn pour prédire la qualité du vin\n",
    "#### on utilise SearchGridCV pour rechercher le meilleur hyper-paramètre k du modèle Knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "# Créer une régression kNN avec recherche d'hyperparamètre par validation croisée\n",
    "knn = model_selection.GridSearchCV(neighbors.KNeighborsRegressor(),\n",
    "    param_grid = {'n_neighbors':[3, 5, 7, 9, 11, 13, 15]}, # hyperparamètres à tester\n",
    "    cv=5, # nombre de folds de validation croisée\n",
    "    scoring='neg_mean_squared_error' # choisissons l’erreur quadratique moyenne comme score à optimiser\n",
    "    )                            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etant donné que l'algorithme GridSearchCV classe les modèles en maximisant la valeur calculée par \"scoring\", on est obligé d'utiliser - mean_square_error. En effet un modèle avec une mean_squarred_error élevé est moins bon qu'on modèle avec une mean_squarred_error_ faible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "          metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "          weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': [3, 5, 7, 9, 11, 13, 15]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimiser la régression sur le jeu d'entraînement\n",
    "knn.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\n",
      "{'n_neighbors': 13}\n",
      "Résultats de la validation croisée :\n",
      "\tMean Squarred Error = 0.512 (+/-0.087) for {'n_neighbors': 3}\n",
      "\tMean Squarred Error = 0.485 (+/-0.073) for {'n_neighbors': 5}\n",
      "\tMean Squarred Error = 0.458 (+/-0.073) for {'n_neighbors': 7}\n",
      "\tMean Squarred Error = 0.443 (+/-0.067) for {'n_neighbors': 9}\n",
      "\tMean Squarred Error = 0.441 (+/-0.061) for {'n_neighbors': 11}\n",
      "\tMean Squarred Error = 0.438 (+/-0.062) for {'n_neighbors': 13}\n",
      "\tMean Squarred Error = 0.441 (+/-0.052) for {'n_neighbors': 15}\n"
     ]
    }
   ],
   "source": [
    "# Afficher le(s) hyperparamètre(s) optimaux\n",
    "print (\"Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\",)\n",
    "print (knn.best_params_)\n",
    "\n",
    "# Afficher les performances correspondantes\n",
    "print (\"Résultats de la validation croisée :\")\n",
    "for mean, std, params in zip(knn.cv_results_['mean_test_score'], # score moyen\n",
    "knn.cv_results_['std_test_score'], # écart-type du score\n",
    "knn.cv_results_['params'] # valeur de l'hyperparamètre\n",
    "):\n",
    "    print (\"\\t%s = %0.3f (+/-%0.03f) for %r\" % ('Mean Squarred Error', # critère utilisé\n",
    "    -mean, # score moyen , on inverse son signe pour afficher mean_squared_error et non pas neg_mean_squared_error\n",
    "    std * 2, # barre d'erreur\n",
    "    params # hyperparamètre\n",
    "    ))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le meilleur hyper-paramètre k pour notre modèle est 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Comparons la performance de ce modèle avec celles de deux modèles naîfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### une première approche naïve, qui consiste à prédire des valeurs aléatoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_random = np.random.randint(np.min(y_train), np.max(y_train), y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### une deuxième méthode naîve basée sur la valeur moyenne de y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import dummy\n",
    "dum = dummy.DummyRegressor(strategy='mean')\n",
    "\n",
    "# Entraînement\n",
    "dum.fit(X_train_std, y_train)\n",
    "\n",
    "# Prédiction sur le jeu de test\n",
    "y_pred_dum = dum.predict(X_test_std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparons les perfomances des modèles naifs et du modèle knn sur le jeu de test : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultats de la méthode naîve basée sur une valeur aléatoire :\n",
      "Mean Squared Error =  2.8375  R2 =  -3.3449595916631214\n",
      "Résultats de la méthode naîve basée sur une valeur constante :\n",
      "Mean Squared Error =  0.6538205550244736  R2 =  -0.0011714156053188596\n",
      "Résultats de la méthode knn avec ses meilleurs paramètres :\n",
      "Mean Squared Error =  0.4469428007889546  R2 =  0.3156128954316306\n"
     ]
    }
   ],
   "source": [
    "# Afficher les performances des méthodes naives\n",
    "\n",
    "print (\"Résultats de la méthode naîve basée sur une valeur aléatoire :\")\n",
    "\n",
    "print (\"Mean Squared Error = \",\n",
    "metrics.mean_squared_error(y_test, y_pred_random), \n",
    "' R2 = ',  \n",
    "metrics.r2_score(y_test, y_pred_random)                                         \n",
    ")\n",
    "\n",
    "print (\"Résultats de la méthode naîve basée sur une valeur constante :\")\n",
    "\n",
    "print (\"Mean Squared Error = \",\n",
    "metrics.mean_squared_error(y_test, y_pred_dum), \n",
    "' R2 = ',  \n",
    "metrics.r2_score(y_test, y_pred_dum)                                         \n",
    ")\n",
    "\n",
    "y_pred_knn = knn.predict(X_test_std)\n",
    "print (\"Résultats de la méthode knn avec ses meilleurs paramètres :\")\n",
    "\n",
    "print (\"Mean Squared Error = \",\n",
    "metrics.mean_squared_error(y_test, y_pred_knn), \n",
    "' R2 = ',  \n",
    "metrics.r2_score(y_test, y_pred_knn)                                         \n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Interprétation des valeurs et choix final\n",
    "le meilleur modèle est celui qui minimise l’erreur quadratique moyenne (MSE). Nous avons donc vérifié que notre modèle knn, même s'il n'est pas excellent, est quand mêm meilleur que les 2 modèles naifs étudiés. Il nous apprend donc quand même quelque chose.\n",
    "\n",
    "Notre choix porte sur le modèle knn avec k = 13 (remarque : si on relance le notebook, on constate empriquement que la valeur optimale proposée pour k varie entre 11 et 15)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
