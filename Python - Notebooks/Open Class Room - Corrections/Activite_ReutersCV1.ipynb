{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activité: Classifiez du texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chargement des articles de presse Reuters (à faire 1 seule fois avant de le sauvegarder avec le module pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_rcv1\n",
    "\n",
    "rcv1 = fetch_rcv1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#rcv1.data.shape\n",
    "#rcv1.target.shape\n",
    "#rcv1.sample_id\n",
    "rcv1.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sauvegarde sur disque du jeu de données RCV1 (à faire 1 seule fois avant de le charger avec le module pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "path_to_save = 'C:\\Formation\\Data scientist\\Projet_6\\\\TP\\\\reuters'\n",
    "filename = path_to_save + os.sep + 'rcv1_data.sav'\n",
    "pickle.dump(rcv1.data, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = path_to_save + os.sep + 'rcv1_target.sav'\n",
    "pickle.dump(rcv1.target, open(filename, 'wb'))\n",
    "filename = path_to_save + os.sep + 'rcv1_target_names.sav'\n",
    "pickle.dump(rcv1.target_names, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On charge le dataset RCV1 avec le module pickle, car plus rapide que fetch_rcv1() de sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "path_to_load = 'C:\\Formation\\Data scientist\\Projet_6\\\\TP\\\\reuters'\n",
    "#filename = path_to_save + os.sep + 'rcv1_data.sav'\n",
    "rcv1_data = pickle.load(open(os.path.join(path_to_load, 'rcv1_data.sav'), 'rb'))\n",
    "#filename = path_to_save + os.sep + 'rcv1_target.sav'\n",
    "rcv1_target = pickle.load(open(os.path.join(path_to_load, 'rcv1_target.sav'), 'rb'))\n",
    "#filename = path_to_save + os.sep + 'rcv1_target_names.sav'\n",
    "rcv1_target_names = pickle.load(open(os.path.join(path_to_load, 'rcv1_target_names.sav'), 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0n considère un échantillon de 5000 exemples pour des raisons de capacité calcul et mémoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 47236), (5000, 103))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = rcv1_data[:5000].toarray()\n",
    "y = rcv1_target[:5000].toarray()\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppression du jeu de données global RCV1 pour libérer de la mémoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del rcv1_data, rcv1_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du jeu de données d'entrainement (et de test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Préparation du jeu d'entrainement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3750, 47236), (3750, 103))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage et préparation des données sur y_train et X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Conversion de y_train en dataframe \n",
    "y_train_df = pd.DataFrame(y_train, columns=rcv1_target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CCAT    1866\n",
       "GCAT     983\n",
       "MCAT     943\n",
       "C15      774\n",
       "ECAT     608\n",
       "C151     452\n",
       "M14      403\n",
       "C152     341\n",
       "E21      274\n",
       "M13      262\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nbre d'articles par catégorie\n",
    "nb_articles_per_categ = y_train_df.sum(axis=0)\n",
    "nb_articles_per_categ.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2509    12\n",
       "116     12\n",
       "2042    11\n",
       "2808    11\n",
       "3665    11\n",
       "3659    11\n",
       "180     10\n",
       "3669    10\n",
       "845     10\n",
       "2643    10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nbre de catégories par article\n",
    "nb_categs_per_article = y_train_df.sum(axis=1)\n",
    "nb_categs_per_article.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On a pour ce jeu d'entrainement un nb. de catégories compris entre 1 et 12. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On supprime les catégories qui apparaissent dans moins de 2% de la taille du dataset pour faciliter l'apprentissage des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_categ_freq = 0.02 \n",
    "categ_to_remove = nb_articles_per_categ[nb_articles_per_categ < nb_categ_freq*y_train_df.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nb. de catégories à supprimer\n",
    "len(categ_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppression des 67 catégories sur un total de 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_df.drop(list(categ_to_remove.index), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppression des entrées de y_train et de X_train qui se retrouvent orphelines de catégories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on supprime les entrées sans catégories\n",
    "ix_zero_categ = list(y_train_df[(y_train_df == 0).all(axis=1)].index) \n",
    "y_train_df.drop(ix_zero_categ, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix_zero_categ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Conversion de X_train en dataframe \n",
    "X_train_df = pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# idem sur X_train, pour synchroniser avec y_train\n",
    "X_train_df.drop(ix_zero_categ, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimensions de X_train et y_train avant et après nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avant cleaning: (3750, 47236), (3750, 103)\n",
      "Après cleaning: (3750, 47236), (3750, 36)\n"
     ]
    }
   ],
   "source": [
    "print('Avant cleaning: %s, %s' % (X_train.shape, y_train.shape))\n",
    "print('Après cleaning: %s, %s' % (X_train_df.shape, y_train_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage et préparation des données sur y_test et X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# On reprend les mêmes opérations de data cleaning que pour y_train, X_train\n",
    "y_test_df = pd.DataFrame(y_test, columns=rcv1_target_names)\n",
    "y_test_df.drop(list(categ_to_remove.index), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on supprime les entrées sans catégories\n",
    "ix_zero_categ = list(y_test_df[(y_test_df == 0).all(axis=1)].index) \n",
    "y_test_df.drop(ix_zero_categ, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Conversion de X_test en dataframe \n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "# idem sur X_test, pour synchroniser avec y_test\n",
    "X_test_df.drop(ix_zero_categ, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimensions de X_test et y_test avant et après nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avant cleaning: (1250, 47236), (1250, 103)\n",
      "Après cleaning: (1250, 47236), (1250, 36)\n"
     ]
    }
   ],
   "source": [
    "print('Avant cleaning: %s, %s' % (X_test.shape, y_test.shape))\n",
    "print('Après cleaning: %s, %s' % (X_test_df.shape, y_test_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcul de la densité de zéros dans le jeu de données X_train_df et y_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pcentage de valeurs à 0 dans y_train_df : 0.92064\n",
      "Pcentage de valeurs à 0 dans X_train_df : 0.99986\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sparsity = 1 - np.sum(np.sum(y_train_df)) / (y_train_df.shape[0] * y_train_df.shape[1])\n",
    "print('Pcentage de valeurs à 0 dans y_train_df : %.5f' % sparsity)\n",
    "sparsity = 1 - np.sum(np.sum(X_train_df)) / (X_train_df.shape[0] * X_train_df.shape[1])\n",
    "print('Pcentage de valeurs à 0 dans X_train_df : %.5f' % sparsity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Le jeu de données d'entrainement reste extrêmement \"creux\" avec une densité de 0 très importante (92 % pour X_train_df et 99.9 % pour y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On est dans tous les cas face à un problème de classification binaire multi-output:\n",
    "-> chaque article Reuters est catégorisé manuellement par 1 ou plusieurs tags (0 = absence du tag, 1 = présence du tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Test d'un classifieur Naive Bayes en mode multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "           n_jobs=-1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nbayes = MultinomialNB()\n",
    "\n",
    "moutput_nbayes = MultiOutputClassifier(nbayes, n_jobs=-1)\n",
    "moutput_nbayes.fit(X_train_df, y_train_df)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = moutput_nbayes.predict(X_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On utilise 2 métriques pour mesurer l'efficacité du modèle sur la prédiction:\n",
    "1) Accuracy score: donne le %tage d'articles pour lesquels l'ensemble des tags associés à chaque article a été correctement prédit <br>\n",
    "2) Hamming loss: donne le %tage de tags incorrectement prédits sur l'ensemble des posts => est plus précis que l'accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.05\n",
      "Hamming loss score:  0.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import hamming_loss, accuracy_score\n",
    "\n",
    "print('Accuracy score: % .2f' % accuracy_score(y_pred, y_test_df) )\n",
    "print('Hamming loss score: % .2f' % (1 - hamming_loss(y_pred, y_test_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation croisée sur l'accuracy score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moyenne des erreurs du modèle : 0.0434666666667\n",
      "Variance des erreurs du modèle : 0.00645531649969\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    " \n",
    "scores = cross_val_score(moutput_nbayes, X_train_df, y_train_df, cv=5)\n",
    "print('Moyenne des erreurs du modèle :', scores.mean())\n",
    "print('Variance des erreurs du modèle :', scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2. Test d'une Régression logistique en mode multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "           n_jobs=-1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "moutput_logreg = MultiOutputClassifier(logreg, n_jobs=-1)\n",
    "moutput_logreg.fit(X_train_df, y_train_df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = moutput_logreg.predict(X_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.26\n",
      "Hamming loss score:  0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import hamming_loss, accuracy_score\n",
    "\n",
    "print('Accuracy score: % .2f' % accuracy_score(y_pred, y_test_df) )\n",
    "print('Hamming loss score: % .2f' % (1 - hamming_loss(y_pred, y_test_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation croisée sur l'accuracy score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moyenne des erreurs du modèle : 0.2288\n",
      "Variance des erreurs du modèle : 0.0116420693082\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    " \n",
    "scores = cross_val_score(moutput_logreg, X_train_df, y_train_df, cv=5)\n",
    "print('Moyenne des erreurs du modèle :', scores.mean())\n",
    "print('Variance des erreurs du modèle :', scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3. Test d'un SGD Classifier en mode multi-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l1', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False),\n",
       "           n_jobs=-1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = SGDClassifier(loss=\"log\", penalty='l1')\n",
    "\n",
    "moutput_sgd = MultiOutputClassifier(sgd, n_jobs=-1)\n",
    "moutput_sgd.fit(X_train_df, y_train_df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = moutput_sgd.predict(X_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.45\n",
      "Hamming loss score:  0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import hamming_loss, accuracy_score\n",
    "\n",
    "print('Accuracy score: % .2f' % accuracy_score(y_pred, y_test_df) )\n",
    "print('Hamming loss score: % .2f' % (1 - hamming_loss(y_pred, y_test_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation croisée sur l'accuracy score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moyenne des erreurs du modèle : 0.433866666667\n",
      "Variance des erreurs du modèle : 0.0174986983643\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    " \n",
    "scores = cross_val_score(moutput_sgd, X_train_df, y_train_df, cv=5)\n",
    "print('Moyenne des erreurs du modèle :', scores.mean())\n",
    "print('Variance des erreurs du modèle :', scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion: il est possible d'obtenir un score satisfaisant du point de vue du Hamming loss avec les 3 classifieurs, sinon le SGD Classifier obtient le meilleur accuracy score (45 %) loin devant les deux autres et cela après entrainement sur seulement 3750 articles Reuters.\n",
    "Dans tous les cas, l'accuracy score est bien plus contraignant car il faut pouvoir prédire pour un article Reuters TOUTES les catégories (soit les 36 catégories) de manière correcte sans exception. De plus il faudrait entrainer les modèles sur l'intégralité du dataset (800000 articles) pour avoir de meilleurs résultats mais les capacités machine ne me le permettent pas.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Il serait également intéressant de pouvoir réduire la dimension de X_train avec 47236, de plus cela permettrait de gagner en performance machine (calcul, mémoire..)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
