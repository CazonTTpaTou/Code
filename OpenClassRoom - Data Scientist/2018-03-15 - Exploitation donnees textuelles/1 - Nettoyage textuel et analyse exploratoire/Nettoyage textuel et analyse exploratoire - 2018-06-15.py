
# coding: utf-8

# # TP - Nettoyage textuel et analyse exploratoire

# In[2]:


from IPython.display import Image
from IPython.core.display import HTML 
Image(filename = "DiagrammeClasses.png")


# # Classes du programme

# ## Classe ETL

# In[120]:


import pickle
import os
import numpy as np 

from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer

#from Document import Document

class ETL:

    def __init__(self,path):
        self.path = path
        os.chdir(path)
        
        self.listeDocuments = []
        
        self.FrequenceMotsHighLights = {}
        self.FrequenceMotsArticles = {}
        
        self.Matrice_TF_IDF_HighLights = {}
        self.Matrice_TF_IDF_Articles = {}
    
    def retourner_calcul_frequence_mots(self):
        for index,document in enumerate(self.listeDocuments):
            print('Document n° {} ----------------------'.format(index+1))
            print('Fréquence de mots HighLight : -------')
            print(document.Retourner_HighLigtht_Frequence())
            
            print('Fréquence de mots Article : -------')
            print(document.Retourner_Article_Frequence())
            print('-----------------------------------')
            
    def retourner_calcul_matrice_idf(self):
        for index,document in enumerate(self.listeDocuments):
            print('Document n° {} ----------------------'.format(index+1))
            print('Matrice TF-IDF HighLight : -------')
            print(document.Retourner_HighLigtht_Matrice_TF_IDF())
            
            print('Matrice TF-IDF Article : -------')
            print(document.Retourner_Article_Matrice_TF_IDF())
            print('-----------------------------------')
            
    def retourner_calcul_matrice_idf_global_Highlight(self):
        corpus = []
        
        for index,document in enumerate(self.listeDocuments):
            corpus.append(document.highLights.returnText())
            
        cvec = CountVectorizer(
                                lowercase=True,        
                                tokenizer=None,        
                                token_pattern=r'\w+')  

        term_freq = cvec.fit_transform(corpus)
        
        matrice_tfidf = TfidfTransformer().fit_transform(term_freq)
        
        return matrice_tfidf        

    def retourner_calcul_matrice_idf_global_Article(self):
        corpus = []
        
        for index,document in enumerate(self.listeDocuments):
            corpus.append(document.article.returnText())
            
        cvec = CountVectorizer(
                                lowercase=True,        
                                tokenizer=None,        
                                token_pattern=r'\w+')  

        term_freq = cvec.fit_transform(corpus)
        
        matrice_tfidf = TfidfTransformer().fit_transform(term_freq)
        
        return matrice_tfidf 
    
    def creation_Dictionnaire_HighLight_TF_IDF(self):
        for index,document in enumerate(self.listeDocuments):            
            for items in document.Retourner_HighLigtht_Matrice_TF_IDF():
                try:
                    self.Matrice_TF_IDF_HighLights[items.todok().keys()]+=1
                except:
                    try:
                        self.Matrice_TF_IDF_HighLights[items.todok().keys()]=1                       
                    except:
                        pass
        
        return self.Matrice_TF_IDF_HighLights
    
    def creation_Dictionnaire_Article_TF_IDF(self):
        for index,document in enumerate(self.listeDocuments):            
            for items in document.Retourner_Article_Matrice_TF_IDF():
                try:
                    self.Matrice_TF_IDF_Article[items.todok().keys()]+=1
                except:
                    try:
                        self.Matrice_TF_IDF_Article[items.todok().keys()]=1                       
                    except:
                        pass
        
        return self.Matrice_TF_IDF_Article
            
    def creation_Dictionnaire_HighLight_Frequence_Mots(self):
        for index,document in enumerate(self.listeDocuments):
            for items in document.Retourner_HighLigtht_Frequence():
                try:
                    self.FrequenceMotsHighLights[items[0]]+=items[1]
                except:
                    self.FrequenceMotsHighLights[items[0]]=items[1]
        
        return self.FrequenceMotsHighLights
    
    def creation_Dictionnaire_Article_Frequence_Mots(self):
        for index,document in enumerate(self.listeDocuments):
            for items in document.Retourner_Article_Frequence():
                try:
                    self.FrequenceMotsArticles[items[0]]+=items[1]
                except:
                    self.FrequenceMotsArticles[items[0]]=items[1]
        
        return self.FrequenceMotsArticles

    def retournerRepertoireSauvegarde(self):
        repertoireBackUp = self.path 
        return repertoireBackUp

    def Lecture_Fichiers(self):
        listeFichiers = os.listdir(self.path)
        
        for fichier in listeFichiers:
            self.Creer_Document(fichier)
    
    def read_File(self,nameFile):
        
        Content = {}
        
        with open(nameFile,"rb") as myFile:
            myString = str(myFile.read())
            Content['Texte'] = myString[:int(myString.find('@highlight'))]
            Content['HighLight'] = myString[int(myString.find('@highlight')):]
            
        return Content

    def Creer_Document(self,nomFichier):
        fichier = self.read_File(nomFichier)
        
        document = Document(
                        fichier['Texte'],
                        fichier['HighLight'])
        
        self.listeDocuments.append(document)

    def enregistrerListeFichiers(self):
        for document in self.listeDocuments:
            self.Enregistrer_Document(
                                document.Retourner_Numero_Document()) 

    def Enregistrer_Element(self,numeroDocument,contenu,suffixe):
        os.chdir(self.retournerRepertoireSauvegarde())
        
        nameFile = "Document_" + str(numeroDocument) + suffixe
        
        with open(nameFile,"wb") as myFichier:
            monPickler = pickle.Pickler(myFichier)
            monPickler.dump(contenu)

    def Enregistrer_Document(self,numeroDocument):       
        self.Enregistrer_Element(
                            numeroDocument,
                            self.listeDocuments[numeroDocument-1].Retourner_Article_Normalise(),
                            '_Article')
        
        self.Enregistrer_Element(
                            numeroDocument,
                            self.listeDocuments[numeroDocument-1].Retourner_HighLigtht_Normalise(),
                            '_HighLights')

    def Charger_Element(self,numeroDocument,suffixe):
        os.chdir(self.retournerRepertoireSauvegarde())
        
        nameFile = "Document_" + str(numeroDocument) + suffixe
        
        with open(nameFile,"rb") as myFichiers:
            monDe_Pickler = pickle.Unpickler(myFichiers)
            return  monDe_Pickler.load()

    def Charger_Document(self,numeroDocument):
        print('------------------------------')
        print('ARTICLE N° {} '.format(numeroDocument))
        print('------------------------------')
        print(
                self.Charger_Element(
                                    numeroDocument,
                                    '_Article'))
        
        print('------------------------------')
        print('HIGHLIGHTS N° {} '.format(numeroDocument))
        print('------------------------------')
        print(
                self.Charger_Element(
                                    numeroDocument,
                                    '_HighLights'))           
        


# ## Classe Document

# In[79]:


#from Texte import Texte

class Document:

    numeroDocumentGlobal = 0
    
    @classmethod
    def IncrementIdentifiant(self):
        self.numeroDocumentGlobal += 1    
    
    def __init__(self, textArticle, textHighLights):
        self.IncrementIdentifiant()
        self.numeroDocument = self.numeroDocumentGlobal
        
        self.article = Texte(textArticle)        
        self.highLights = Texte(textHighLights)
        
        self.Afficher_Caracteristiques_Document()
        
    def Retourner_Numero_Document(self):
        return self.numeroDocument
   
    def Retourner_Article_Normalise(self):
        return self.article.returnTextNormalised()
        
    def Retourner_HighLigtht_Normalise(self):
        return self.highLights.returnTextNormalised()

    def Retourner_Article_Frequence(self):
        return self.article.ListeMotsTriee
        
    def Retourner_HighLigtht_Frequence(self):
        return self.highLights.ListeMotsTriee
    
    def Retourner_Article_Matrice_TF_IDF(self):
        return self.article.retourner_Matrice_TF_IDF()
        
    def Retourner_HighLigtht_Matrice_TF_IDF(self):
        return self.highLights.retourner_Matrice_TF_IDF()

    def Afficher_Caracteristiques_Document(self):
        print('--------------------------------------')
        print('Caractéristiques du document {}'.format(self.Retourner_Numero_Document()))
        print('--------------------------------------')
        print('HIGHLIGHTS du document {}'.format(self.Retourner_Numero_Document()))
        self.highLights.AfficherStatistiques()               
        print('ARTICLES du document {}'.format(self.Retourner_Numero_Document()))
        print('--------------------------------------')
        self.article.AfficherHistogramme()



# ## Classe Texte

# In[80]:


import nltk
import pandas as pd
from operator import itemgetter

class Texte:
    
    def __init__(self,stringData):
        self.textContent = stringData
        
        self.textContentNormalized = self.Suppression_StopWords(
                                        self.Suppression_Ponctuation(
                                                    self.decodage_UTF8(
                                                            self.returnText())))

    def returnText(self):
        return self.textContent

    def returnTextNormalised(self):
                
        return self.textContentNormalized
    
    def returnStatistiques(self):
        self.Frequence_Mots()
        
        return self.statsMots
        
    def decodage_UTF8(self,text):
        by = bytes(text,'utf-8')
        textDecode = by.decode('utf-8').lower()
        
        return textDecode

    def Suppression_Ponctuation(self,text):
        tokenizer = nltk.RegexpTokenizer(r'\w+')
        tokenisation = tokenizer.tokenize(text)
        
        return tokenisation        
        
    def Suppression_StopWords(self,text):
        texteSansStopWords = []
        nltk.download('stopwords')
        
        listeStopWord = nltk.corpus.stopwords.words('english')
        listeStopWord.append('â')
        listeStopWord.append('n')
        listeStopWord.append('xc2')
        listeStopWord.append('xc3')
        listeStopWord.append('000')
        
        texteSansStopWords += [word for word in text if not word in listeStopWord]
        
        return texteSansStopWords
    
    def Frequence_Mots(self):
        stats = nltk.FreqDist(self.textContentNormalized)
        self.NombreMots = len(self.textContentNormalized)
        self.NombreMotsUniques = len(stats)
        self.ListeMotsTriee = sorted(stats.items(),key=itemgetter(1),reverse=True)
        self.statsMots = stats
        
    def Analyse_Matrice_TF_IDF(self,Phrases):
        cvec = CountVectorizer(
                                lowercase=True,        
                                tokenizer=None,        
                                token_pattern=r'\w+')  

        term_freq = cvec.fit_transform(Phrases)
        phrases_tfidf = TfidfTransformer().fit_transform(term_freq)
        
        self.matrice_TF_IDF = phrases_tfidf

    def retourner_Matrice_TF_IDF(self):
        try:
            self.Analyse_Matrice_TF_IDF(self.textContentNormalized)
        
            return self.matrice_TF_IDF
        except:
            return [[1]]
        
    def AfficherStatistiques(self):
        self.Frequence_Mots()
        
        print('--------------------------------------')
        print('Le texte comporte {} mot(s) '.format(self.NombreMots))
        print('--------------------------------------')
        print('Le texte comporte {} mot(s) unique(s) '.format(self.NombreMotsUniques))
        print('--------------------------------------')
        
        for occurence in self.ListeMotsTriee:
            print('Le mot {} a {} occurrence(s)'.format(occurence[0],occurence[1]))
        print('--------------------------------------')

    def AfficherHistogramme(self):
        donnees = pd.Series(self.returnStatistiques())
        
        donneesTop = donnees.nlargest(20)
        donneesTrieesTop = donneesTop.sort_values(ascending=True)
        
        donneesTrieesTop.plot.barh(color="#318CE7",title="Distribution des 20 occurrences de mots les plus fréquentes")


# # Mise en oeuvre du programme

# ## Importation des données

# In[121]:


imp = ETL("E:\\Data\\RawData\\Exploit_data_texte\\Test")
imp.Lecture_Fichiers()


# ## Calcul des fréquences de mots pour chaque document

# In[104]:


imp.retourner_calcul_frequence_mots()


# ## Fréquence globale des mots pour les documents de type HighLights

# In[55]:


imp.creation_Dictionnaire_HighLight_Frequence_Mots()


# ## Fréquence globale des mots pour les documents de type Articles

# In[56]:


imp.creation_Dictionnaire_Article_Frequence_Mots()


# ## Matrices TF_IDF pour chaque document

# In[82]:


imp.retourner_calcul_matrice_idf()


# ## Calcul de la matrice TF-IDF globale pour les documents de type HighLights

# In[119]:


print(imp.retourner_calcul_matrice_idf_global_Highlight())


# ## Calcul de la matrice TF_IDF globale pour les documents de type Article

# In[122]:


print(imp.retourner_calcul_matrice_idf_global_Article())


# ## Test de l'enregistrement de documents

# In[14]:


imp.enregistrerListeFichiers()


# ## Test du chargement du texte de documents

# In[15]:


imp.Charger_Document(2)

