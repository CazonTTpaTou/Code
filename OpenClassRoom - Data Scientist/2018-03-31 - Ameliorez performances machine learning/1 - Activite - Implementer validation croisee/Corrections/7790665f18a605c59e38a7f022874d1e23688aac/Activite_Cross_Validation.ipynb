{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1/ Préparation des données (identique au TP, sans les graphiques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors, metrics\n",
    "\n",
    "data = pd.read_csv('winequality-white.csv', sep=\";\")\n",
    "\n",
    "X = data.as_matrix(data.columns[:-1])\n",
    "y = data.as_matrix([data.columns[-1]])\n",
    "y = y.flatten()\n",
    "\n",
    "y_class = np.where(y<6, 0, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    model_selection.train_test_split(X, y_class, \n",
    "                                     test_size=0.3 # 30% des données dans le jeu de test\n",
    "                                    )\n",
    "\n",
    "std_scale = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_std = std_scale.transform(X_train)\n",
    "X_test_std = std_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2/ Résultats du TP avec la classe GridSearchCV de Scikit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\n",
      "{'n_neighbors': 15}\n",
      "Résultats de la validation croisée :\n",
      "\taccuracy = 0.749 (+/-0.034) for {'n_neighbors': 3}\n",
      "\taccuracy = 0.750 (+/-0.024) for {'n_neighbors': 5}\n",
      "\taccuracy = 0.748 (+/-0.025) for {'n_neighbors': 7}\n",
      "\taccuracy = 0.754 (+/-0.031) for {'n_neighbors': 9}\n",
      "\taccuracy = 0.756 (+/-0.028) for {'n_neighbors': 11}\n",
      "\taccuracy = 0.754 (+/-0.030) for {'n_neighbors': 13}\n",
      "\taccuracy = 0.758 (+/-0.022) for {'n_neighbors': 15}\n",
      "\n",
      "Sur le jeu de test : 0.776\n"
     ]
    }
   ],
   "source": [
    "# Code du TP avec la classe GridSearchCV de Scikit\n",
    "\n",
    "# Fixer les valeurs des hyperparamètres à tester\n",
    "param_grid = {'n_neighbors':[3, 5, 7, 9, 11, 13, 15]}\n",
    "\n",
    "# Choisir un score à optimiser, ici l'accuracy (proportion de prédictions correctes)\n",
    "score = 'accuracy'\n",
    "\n",
    "# Créer un classifieur kNN avec recherche d'hyperparamètre par validation croisée\n",
    "clf = model_selection.GridSearchCV(neighbors.KNeighborsClassifier(), # un classifieur kNN\n",
    "param_grid, # hyperparamètres à tester\n",
    "cv=5, # nombre de folds de validation croisée\n",
    "scoring=score # score à optimiser\n",
    ")\n",
    "\n",
    "# Optimiser ce classifieur sur le jeu d'entraînement\n",
    "# clf.fit(X_train, y_train)\n",
    "clf.fit(X_train_std, y_train)\n",
    "\n",
    "# Afficher le(s) hyperparamètre(s) optimaux\n",
    "print(\"Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\")\n",
    "print(clf.best_params_)\n",
    "\n",
    "# Afficher les performances correspondantes\n",
    "print(\"Résultats de la validation croisée :\")\n",
    "for mean, std, params in zip(clf.cv_results_['mean_test_score'], # score moyen\n",
    "clf.cv_results_['std_test_score'], # écart-type du score\n",
    "clf.cv_results_['params'] # valeur de l'hyperparamètre\n",
    "):\n",
    "    print(\"\\t%s = %0.3f (+/-%0.03f) for %r\" % (\n",
    "        score, # critère utilisé \n",
    "        mean, # score moyen \n",
    "        std * 2, # barre d'erreur \n",
    "        params # hyperparamètre \n",
    "        ))\n",
    "\n",
    "y_pred_scikit = clf.predict(X_test_std)\n",
    "print(\"\\nSur le jeu de test : %0.3f\" % metrics.accuracy_score(y_test, y_pred_scikit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3/ Nouveaux résultats avec la classe créée : KnnGridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cette classe s'utilise de la même manière que celle de Scikit, à savoir:\n",
    "_ Initialisation avec la liste des paramètres à tester et le nombre de folds\n",
    "\n",
    "_ Une fonction fit pour tester les différents paramètres et trouver le meilleur\n",
    "\n",
    "_ Une fonction predict pour appliquer le meilleur modèle trouvé avec fit à un jeu de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\n",
      "15\n",
      "Résultats de la validation croisée :\n",
      "\taccuracy = 0.749 (+/-0.034) for 3\n",
      "\taccuracy = 0.750 (+/-0.024) for 5\n",
      "\taccuracy = 0.748 (+/-0.025) for 7\n",
      "\taccuracy = 0.754 (+/-0.031) for 9\n",
      "\taccuracy = 0.756 (+/-0.028) for 11\n",
      "\taccuracy = 0.754 (+/-0.030) for 13\n",
      "\taccuracy = 0.758 (+/-0.022) for 15\n",
      "\n",
      "Sur le jeu de test : 0.776\n"
     ]
    }
   ],
   "source": [
    "from KnnGridSearchCV import KnnGridSearchCV\n",
    "\n",
    "# Fixer les valeurs des hyperparamètres à tester\n",
    "param_grid = {'n_neighbors':[3, 5, 7, 9, 11, 13, 15]}\n",
    "\n",
    "# Ici la classe créée ne prend en paramètres que la liste des hyperparamètres\n",
    "# et le nombre de folds\n",
    "clf = KnnGridSearchCV(param_grid['n_neighbors'], # hyperparamètres à tester\n",
    "                      nb_folds=5, # nombre de folds de validation croisée\n",
    "                     )\n",
    "\n",
    "# Optimiser ce classifieur sur le jeu d'entraînement\n",
    "clf.fit(X_train_std, y_train)\n",
    "\n",
    "# Afficher le(s) hyperparamètre(s) optimaux\n",
    "print(\"Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\")\n",
    "print(clf.best_params_)\n",
    "\n",
    "# Afficher les performances correspondantes\n",
    "print(\"Résultats de la validation croisée :\")\n",
    "for mean, std, params in zip(clf.cv_results_['mean_test_score'], # score moyen\n",
    "clf.cv_results_['std_test_score'], # écart-type du score\n",
    "clf.cv_results_['params'] # valeur de l'hyperparamètre\n",
    "):\n",
    "    print(\"\\t%s = %0.3f (+/-%0.03f) for %r\" % (\n",
    "        score, # critère utilisé \n",
    "        mean, # score moyen \n",
    "        std * 2, # barre d'erreur \n",
    "        params # hyperparamètre \n",
    "        ))\n",
    "\n",
    "y_pred_new = clf.predict(X_test_std)\n",
    "print(\"\\nSur le jeu de test : %0.3f\" % metrics.accuracy_score(y_test, y_pred_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les résultats sont identiques mais on peut vérifier aussi que les deux fonctions donnent bien le même résultat final sur le jeu de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test, y_pred_scikit) == metrics.accuracy_score(y_test, y_pred_new))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
