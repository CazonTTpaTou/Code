{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import neighbors, metrics\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Ré-implémentation d'une fonction de validation croisée\n",
    "La fonction prend en entrée :\n",
    "- le jeu d'entraînement,  \n",
    "- les hyper-paramètres à tester,\n",
    "- le nombre de folds pour la validation croisée\n",
    "\n",
    "La fonction retourne :\n",
    "- les résultats pour chaque valeur de l'hyperparamètre (mean, std)\n",
    "- les valeurs testées pour l'hyper-paramètre\n",
    "- la meilleure valeur pour l'hyper-paramètre \n",
    "- les sets train/test des folds pour pouvoir réutiliser les mêmes sets pour comparaison avec la fonction SearchGridCV\n",
    "- le modèle entraîné avec le meilleur hyper-paramètre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_croisee(X,y,parameters, n_folds) :   \n",
    "    \n",
    "    # constitutons les folds : sets de données train/test\n",
    "    kf = KFold(n_splits = n_folds)            \n",
    "    \n",
    "    best_score = 0\n",
    "    best_params = 0\n",
    "    mean_values = []\n",
    "    std_values = []\n",
    "    \n",
    "    # pour chaque valeur d'hyper-paramètre, calcul de la moyenne du score obtenu sur chaque fold\n",
    "    for num_neighbors in parameters :\n",
    "        scores = []\n",
    "        \n",
    "        # pour chaque set de données (fold), entraînement du modèle sur les données train et score sur les données test\n",
    "        \n",
    "        for train_index, test_index in kf.split(X) :\n",
    "            X_CV_train, X_CV_test = X[train_index], X[test_index]\n",
    "            y_CV_train, y_CV_test = y[train_index], y[test_index]    \n",
    "\n",
    "            knn = neighbors.KNeighborsClassifier(n_neighbors=num_neighbors)\n",
    "            knn.fit(X_CV_train, y_CV_train)\n",
    "            score = knn.score(X_CV_test, y_CV_test)\n",
    "            scores.append(score)\n",
    "            \n",
    "        # moyenne des scores pour num_neighbors fixé\n",
    "        mean = np.mean(scores)\n",
    "        mean_values.append(mean)\n",
    "        std = np.std(scores)\n",
    "        std_values.append(std)\n",
    "        \n",
    "        # mémorisation du meilleuir score et de l'hyper-paramètre associé\n",
    "        if mean>best_score :\n",
    "            best_score=mean\n",
    "            best_params_ = num_neighbors\n",
    "            best_knn = knn\n",
    "        \n",
    "    #on retourne les sets de données pour pouvoir les utiliser pour une comparaison avec searchGridCV sur des données identiques\n",
    "    return({'mean_test_score' : mean_values, 'std_test_score' : std_values, 'params' : parameters, 'best_params_' :best_params_ , 'folds' : kf, 'trained_knn' : best_knn })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) comparaison des résultats d'évaluation avec la fonction de validation croisée ré-implémentée et la fonction SearchGridCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('winequality-white.csv', sep = \";\")\n",
    "data.head()\n",
    "\n",
    "X = data.as_matrix(data.columns[:-1])\n",
    "y = data.as_matrix([data.columns[-1]])\n",
    "y = y.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation en données d'entraînement et données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "\tmodel_selection.train_test_split(X, y,\n",
    "                                \ttest_size=0.3 # 30% des données dans le jeu de test\n",
    "                                \t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "std_scale = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_std = std_scale.transform(X_train)\n",
    "X_test_std = std_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### comparaison des résultats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nouvelle implémentation de la fonction de cross validation\n",
      "===========================================================\n",
      "Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\n",
      "7\n",
      "Résultats de la validation croisée :\n",
      "\taccuracy = 0.518 (+/-0.054) for 3\n",
      "\taccuracy = 0.536 (+/-0.040) for 5\n",
      "\taccuracy = 0.543 (+/-0.037) for 7\n",
      "\taccuracy = 0.539 (+/-0.043) for 9\n",
      "\taccuracy = 0.538 (+/-0.036) for 11\n",
      "\taccuracy = 0.537 (+/-0.035) for 13\n",
      "\taccuracy = 0.536 (+/-0.029) for 15\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters = [3, 5, 7, 9, 11, 13, 15]\n",
    "n_folds = 5\n",
    "\n",
    "# lance la fonction de cross validation sur les données d'entraînement\n",
    "# retourne kf = les sets de données des folds pour pouvoir réutiliser les mêmes avec la fonction GrisSearcgCV, pour comparaison sur de sets identiques\n",
    "\n",
    "results_validation_croisee = validation_croisee(X_train_std, y_train, parameters, n_folds)\n",
    "    \n",
    "# Afficher le(s) hyperparamètre(s) optimaux\n",
    "print(\"nouvelle implémentation de la fonction de cross validation\")\n",
    "print(\"===========================================================\")\n",
    "\n",
    "# Afficher le(s) hyperparamètre(s) optimaux\n",
    "print (\"Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\",)\n",
    "print (results_validation_croisee['best_params_'])\n",
    "\n",
    "# Afficher les performances correspondantes\n",
    "print (\"Résultats de la validation croisée :\")\n",
    "for mean, std, params in zip(results_validation_croisee['mean_test_score'], # score moyen\n",
    "results_validation_croisee['std_test_score'], # écart-type du score\n",
    "results_validation_croisee['params'] # valeur de l'hyperparamètre\n",
    "):\n",
    "    print (\"\\t%s = %0.3f (+/-%0.03f) for %r\" % (score, # critère utilisé\n",
    "    mean, # score moyen\n",
    "    std * 2, # barre d'erreur\n",
    "    params # hyperparamètre\n",
    "    ))\n",
    "print('\\n\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "implémentation de la fonction SearchGridCV\n",
      "==========================================\n",
      "Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\n",
      "{'n_neighbors': 7}\n",
      "Résultats de la validation croisée :\n",
      "\taccuracy = 0.518 (+/-0.054) for {'n_neighbors': 3}\n",
      "\taccuracy = 0.536 (+/-0.040) for {'n_neighbors': 5}\n",
      "\taccuracy = 0.543 (+/-0.037) for {'n_neighbors': 7}\n",
      "\taccuracy = 0.539 (+/-0.043) for {'n_neighbors': 9}\n",
      "\taccuracy = 0.538 (+/-0.036) for {'n_neighbors': 11}\n",
      "\taccuracy = 0.537 (+/-0.035) for {'n_neighbors': 13}\n",
      "\taccuracy = 0.536 (+/-0.029) for {'n_neighbors': 15}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fixer les valeurs des hyperparamètres à tester\n",
    "param_grid = {'n_neighbors':parameters}\n",
    "\n",
    "# Choisir un score à optimiser, ici l'accuracy (proportion de prédictions correctes)\n",
    "score = 'accuracy'\n",
    "\n",
    "cv = results_validation_croisee['folds']\n",
    "\n",
    "# Créer un classifieur kNN avec recherche d'hyperparamètre par validation croisée\n",
    "clf = model_selection.GridSearchCV(neighbors.KNeighborsClassifier(), # un classifieur kNN\n",
    "param_grid, # hyperparamètres à tester\n",
    "cv=kf, # nombre de folds de validation croisée\n",
    "scoring=score # score à optimiser\n",
    ")\n",
    "\n",
    "# Optimiser ce classifieur sur le jeu d'entraînement\n",
    "# clf.fit(X_train, y_train)\n",
    "clf.fit(X_train_std, y_train)\n",
    "\n",
    "print(\"implémentation de la fonction SearchGridCV\")\n",
    "print(\"==========================================\")\n",
    "    \n",
    "# Afficher le(s) hyperparamètre(s) optimaux\n",
    "print (\"Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\",)\n",
    "print (clf.best_params_)\n",
    "\n",
    "# Afficher les performances correspondantes\n",
    "print (\"Résultats de la validation croisée :\")\n",
    "for mean, std, params in zip(clf.cv_results_['mean_test_score'], # score moyen\n",
    "clf.cv_results_['std_test_score'], # écart-type du score\n",
    "clf.cv_results_['params'] # valeur de l'hyperparamètre\n",
    "):\n",
    "    print (\"\\t%s = %0.3f (+/-%0.03f) for %r\" % (score, # critère utilisé\n",
    "    mean, # score moyen\n",
    "    std * 2, # barre d'erreur\n",
    "    params # hyperparamètre\n",
    "    ))\n",
    "print('\\n\\n')   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les résultats sont bien identiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Application et évaluation du K-nn avec la fonction de validation croisé ré-implémentée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance du modèle optimisé par la ré-implémentation d'une fonction de validation croisée Sur le jeu de test : 0.544\n"
     ]
    }
   ],
   "source": [
    "parameters = [3, 5, 7, 9, 11, 13, 15]\n",
    "n_folds = 5\n",
    "\n",
    "knn = validation_croisee(X_train_std, y_train, parameters, n_folds)['trained_knn']\n",
    "\n",
    "y_pred = knn.predict(X_test_std)\n",
    "print (\"\\nPerformance du modèle optimisé par la ré-implémentation d'une fonction de validation croisée Sur le jeu de test : %0.3f\" % metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
