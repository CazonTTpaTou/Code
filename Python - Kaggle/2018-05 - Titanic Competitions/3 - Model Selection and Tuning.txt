########################################################################

import pandas as pd

train = pd.read_csv('train_modified.csv')
holdout = pd.read_csv('holdout_modified.csv')

########################################################################

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score

all_X = train.drop(['Survived','PassengerId'],axis=1)
all_y = train['Survived']

lr = LogisticRegression()
scores = cross_val_score(lr,all_X,all_y,cv=10)

accuracy_lr = scores.mean()

########################################################################

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=1)

scores = cross_val_score(knn,all_X,all_y,cv=10)

accuracy_knn = scores.mean()

########################################################################

import matplotlib.pyplot as plt
%matplotlib inline

def plot_dict(dictionary):
    pd.Series(dictionary).plot.bar(figsize=(9,6),
                                   ylim=(0.78,0.83),rot=0)
    plt.show()

knn_scores = dict()

for k in range(1,51,2):
    knn = KNeighborsClassifier(n_neighbors=k)
    scores = cross_val_score(knn,all_X,all_y,cv=10)    
    knn_scores[k] = scores.mean()
    
plot_dict(knn_scores)    

########################################################################

from sklearn.model_selection import GridSearchCV

hyperparameters = {
    "n_neighbors": range(1,20,2),
    "weights": ["distance", "uniform"],
    "algorithm": ['brute'],
    "p": [1,2]
}

knn = KNeighborsClassifier()

grid = GridSearchCV(knn,
                    hyperparameters,
                    cv=10)

grid.fit(all_X,all_y)

best_params = grid.best_params_
best_score = grid.best_score_

########################################################################

from sklearn.model_selection import GridSearchCV

hyperparameters = {
    "n_neighbors": range(1,20,2),
    "weights": ["distance", "uniform"],
    "algorithm": ['brute'],
    "p": [1,2]
}
knn = KNeighborsClassifier()
grid = GridSearchCV(knn,param_grid=hyperparameters,cv=10)

grid.fit(all_X, all_y)

best_params = grid.best_params_
best_score = grid.best_score_

########################################################################

holdout_no_id = holdout.drop(['PassengerId'],axis=1)
best_knn = grid.best_estimator_

holdout_predictions = best_knn.predict(holdout_no_id)

dictionnaire = {
                'PassengerId':holdout['PassengerId'],
                'Survived':holdout_predictions
                }

submission=pd.DataFrame(dictionnaire)

submission.to_csv('submission_1.csv',
                 index=False)

########################################################################

from sklearn.ensemble import RandomForestClassifier

rfc = RandomForestClassifier(random_state=1)

scores = cross_val_score(rfc,
                         all_X,
                         all_y,
                         cv=10)

accuracy_rf = scores.mean()

########################################################################

hyperparameters={            
    'criterion': ["entropy","gini"],
    'max_depth': [5,10],
    'max_features': ["log2","sqrt"],
    'min_samples_leaf': [1, 5],
    'min_samples_split': [3, 5],
    'n_estimators': [6,9]
    }

rcf = RandomForestClassifier(random_state=1)

grid = GridSearchCV(rcf,
                    param_grid=hyperparameters,
                    cv=10)

grid.fit(all_X,all_y)

best_params=grid.best_params_
best_score=grid.best_score_

########################################################################

# The `GridSearchCV` object is stored in memory from
# the previous screen with the variable name `grid`

best_rf=grid.best_estimator_

holdout_predictions = best_rf.predict(holdout_no_id)

submission_df = {'PassengerId':holdout['PassengerId'],
                 'Survived':holdout_predictions}

submission=pd.DataFrame(submission_df)

submission.to_csv('submission_2.csv',
                  header=['PassengerId','Survived'],
                  index=False)

########################################################################
    


